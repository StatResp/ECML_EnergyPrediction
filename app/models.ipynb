{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "measured-bandwidth",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "This notebook covers everything related to Section 4 of the paper (Experiments and Results). This includes model training, hyperparameter search and generates the output files for the evaluation section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "median-cathedral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/mwilbur/code/transit-energy-prediction/app\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "from shapely.geometry import Point, LineString, Polygon, asShape, mapping\n",
    "import requests\n",
    "import numpy as np\n",
    "from shapely.ops import cascaded_union, transform\n",
    "from functools import partial\n",
    "import pyproj\n",
    "#import folium\n",
    "import math\n",
    "import requests\n",
    "import concurrent.futures\n",
    "import json\n",
    "#import plotly\n",
    "from scipy import stats\n",
    "import sklearn.metrics\n",
    "import pickle\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "#from matplotlib import cm, colors\n",
    "#import seaborn as sn\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "os.chdir(\"../\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polish-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suffering-alexandria",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = ['precipitation_intensity', 'temperature', 'humidity', 'wind_speed', 'wind_gust', 'visibility', 'speed_meters_per_second', 'sr_ave_trip', 'jf_ave_trip', 'secondary', 'motorway_link', 'secondary_link', 'trunk', 'unclassified', 'motorway', 'residential', 'tertiary', 'primary_link', 'primary', 'elevation_diff', 'actual_elevation_change', 'distance_travelled_m']\n",
    "TARGET = 'target_kg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wired-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_point(row, pref):\n",
    "    return Point(row[f\"{pref}_stop_lon\"], row[f\"{pref}_stop_lat\"])\n",
    "\n",
    "\n",
    "def format_segments(df, add_stop_points=True, trip_id_format=False):\n",
    "    df = df.set_geometry('geometry')\n",
    "    df['trip_id'] = df['trip_id'].astype(int)\n",
    "    df['segment_seq'] = df['segment_seq'].astype(int)\n",
    "    df['start_stop_id'] = df['start_stop_id'].astype(int)\n",
    "    df['end_stop_id'] = df['end_stop_id'].astype(int)\n",
    "    df['direction_id'] = df['direction_id'].astype(int)\n",
    "    df['route_id'] = df['route_id'].astype(str)\n",
    "    df['distance_btw_stops'] = df['distance_btw_stops'].astype(float)\n",
    "    df['start_stop_name'] = df['start_stop_name'].astype(str)\n",
    "    df['end_stop_name'] = df['end_stop_name'].astype(str)\n",
    "    df['distance_m'] = df['distance_m'].astype(float)\n",
    "    df['gtfs_start_date'] = df['gtfs_start_date'].apply(lambda x: datetime.date.fromisoformat(x))\n",
    "    df['gtfs_end_date'] = df['gtfs_end_date'].apply(lambda x: datetime.date.fromisoformat(x))\n",
    "    df['segment_id'] = df['segment_id'].astype(str)\n",
    "    \n",
    "    df['XDSegID'] = df['XDSegID'].apply(lambda x: apply_format_list(x, col_type='int'))\n",
    "    df['osm_ways'] = df['osm_ways'].apply(lambda x: apply_format_list(x, col_type='int'))\n",
    "    df['tmc_id'] = df['tmc_id'].apply(lambda x: apply_format_list(x, col_type='string'))\n",
    "    df['osm_way_fclasses'] = df['osm_way_fclasses'].apply(lambda x: apply_format_list(x, col_type='string'))\n",
    "    df['elevation_list'] = df['elevation_list'].apply(lambda x: apply_format_list(x, col_type='float'))\n",
    "    \n",
    "    if add_stop_points:\n",
    "        df['start_stop_geometry'] = df.apply(lambda row: get_point(row, 'start'), axis=1)\n",
    "        df['end_stop_geometry'] = df.apply(lambda row: get_point(row, 'end'), axis=1)\n",
    "        df = df.drop(columns=['start_stop_lon', 'start_stop_lat', 'end_stop_lat', 'end_stop_lon'])\n",
    "    else:\n",
    "        df['start_stop_lon'] = df['start_stop_lon'].astype(float)\n",
    "        df['end_stop_lon'] = df['end_stop_lon'].astype(float)\n",
    "        df['start_stop_lat'] = df['start_stop_lat'].astype(float)\n",
    "        df['end_stop_lat'] = df['end_stop_lat'].astype(float)\n",
    "    if trip_id_format:\n",
    "        df['trip_id'] = df['trip_id'].apply(lambda x: int(str(int(x))[0:-3]))\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_format_list(x, col_type='int'):\n",
    "    if isinstance(x, str):\n",
    "        x = x.replace(\"[\", \"\")\n",
    "        x = x.replace(\"]\", \"\")\n",
    "        x = x.replace(\" \", \"\")\n",
    "        x = x.replace(\"'\", \"\")\n",
    "        if col_type == 'int':\n",
    "            return [int(y) for y in x.split(\",\")]\n",
    "        elif col_type == 'float':\n",
    "            return [float(y) for y in x.split(\",\")]\n",
    "        elif col_type == \"string\":\n",
    "            return [str(y) for y in x.split(\",\")]\n",
    "        else:\n",
    "            return [y for y in x.split(\",\")]\n",
    "            \n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def remove_trips_with_duplicates(df):\n",
    "    print(f\"Number of unique trips: {len(df['trip_id'].unique())}\")\n",
    "    trips_to_keep = []\n",
    "    for trip_id in df['trip_id'].unique():\n",
    "        temp = df[df['trip_id']==trip_id]\n",
    "        if len(temp['start_stop_id'].unique()) == len(temp):\n",
    "            trips_to_keep.append(trip_id)\n",
    "    result = df[df['trip_id'].isin(trips_to_keep)]\n",
    "    print(f\"Number of trips without duplicate stops: {len(result['trip_id'].unique())}\")\n",
    "    return df[df['trip_id'].isin(trips_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-sweden",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(), 'output_r', 'segments', 'segments.pkl') \n",
    "DF_SEG = pd.read_pickle(file_path)\n",
    "DF_SEG = format_segments(DF_SEG, add_stop_points=True, trip_id_format=True)\n",
    "DF_SEG = remove_trips_with_duplicates(DF_SEG)\n",
    "DF_SEG['geometry_proj'] = DF_SEG.to_crs('EPSG:32616')['geometry']\n",
    "DF_SEG.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "promotional-guest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358861\n",
      "350413\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitation_intensity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_gust</th>\n",
       "      <th>visibility</th>\n",
       "      <th>sr_ave_trip</th>\n",
       "      <th>jf_ave_trip</th>\n",
       "      <th>secondary</th>\n",
       "      <th>motorway_link</th>\n",
       "      <th>secondary_link</th>\n",
       "      <th>trunk</th>\n",
       "      <th>unclassified</th>\n",
       "      <th>motorway</th>\n",
       "      <th>residential</th>\n",
       "      <th>tertiary</th>\n",
       "      <th>primary_link</th>\n",
       "      <th>primary</th>\n",
       "      <th>elevation_diff</th>\n",
       "      <th>actual_elevation_change</th>\n",
       "      <th>distance_travelled_m</th>\n",
       "      <th>target_kg_per_km</th>\n",
       "      <th>target_kg</th>\n",
       "      <th>vehicle_class</th>\n",
       "      <th>time_to_travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>41.47</td>\n",
       "      <td>0.94</td>\n",
       "      <td>7.68</td>\n",
       "      <td>24.73</td>\n",
       "      <td>4.125</td>\n",
       "      <td>0.965237</td>\n",
       "      <td>0.24824</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>234.224653</td>\n",
       "      <td>1.337093</td>\n",
       "      <td>0.31318</td>\n",
       "      <td>electric</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precipitation_intensity  temperature  humidity  wind_speed  wind_gust  \\\n",
       "0                      0.0        41.47      0.94        7.68      24.73   \n",
       "\n",
       "   visibility  sr_ave_trip  jf_ave_trip  secondary  motorway_link  \\\n",
       "0       4.125     0.965237      0.24824          1              0   \n",
       "\n",
       "   secondary_link  trunk  unclassified  motorway  residential  tertiary  \\\n",
       "0               0      0             0         0            0         0   \n",
       "\n",
       "   primary_link  primary  elevation_diff  actual_elevation_change  \\\n",
       "0             0        0            0.73                    -0.54   \n",
       "\n",
       "   distance_travelled_m  target_kg_per_km  target_kg vehicle_class  \\\n",
       "0            234.224653          1.337093    0.31318      electric   \n",
       "\n",
       "   time_to_travel  \n",
       "0            32.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(os.getcwd(), 'output_r', 'training', 'data2.pkl')\n",
    "DF = pd.read_pickle(file_path)\n",
    "keep_cols = FEATURE_COLUMNS + ['target_kg_per_km', 'target_kg', 'vehicle_class']\n",
    "DF = DF[keep_cols]\n",
    "print(len(DF))\n",
    "DF = DF.dropna()\n",
    "print(len(DF))\n",
    "DF['time_to_travel'] = DF.apply(lambda row: 1 / (row['speed_meters_per_second'] / row['distance_travelled_m']), axis=1)\n",
    "DF = DF.drop(columns=['speed_meters_per_second'])\n",
    "FEATURE_COLUMNS = ['precipitation_intensity', 'temperature', 'humidity', 'wind_speed', 'wind_gust', 'visibility', 'time_to_travel', 'sr_ave_trip', 'jf_ave_trip', 'secondary', 'motorway_link', 'secondary_link', 'trunk', 'unclassified', 'motorway', 'residential', 'tertiary', 'primary_link', 'primary', 'elevation_diff', 'actual_elevation_change', 'distance_travelled_m']\n",
    "#DF['elevation_change'] = DF['actual_elevation_change']\n",
    "#DF = DF.drop(columns=['actual_elevation_change'])\n",
    "DF.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-support",
   "metadata": {},
   "source": [
    "## 1. Data Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['ave_speed'] = DF.apply(lambda row: (row['distance_travelled_m'] / row['time_to_travel']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_energy_kwh(row):\n",
    "    if row['vehicle_class'] == 'electric':\n",
    "        return row['target_kg'] / 0.707\n",
    "    else:\n",
    "        return (row['target_kg'] / 10.18) * 37.95\n",
    "\n",
    "DF['kwh'] = DF.apply(lambda row: get_energy_kwh(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average diesel: {DF[DF['vehicle_class']=='diesel']['kwh'].mean()}, average hybrid {DF[DF['vehicle_class']=='hybrid']['kwh'].mean()}, average electric {DF[DF['vehicle_class']=='electric']['kwh'].mean()}\")\n",
    "print(f\"median diesel: {DF[DF['vehicle_class']=='diesel']['kwh'].median()}, median hybrid {DF[DF['vehicle_class']=='hybrid']['kwh'].median()}, median electric {DF[DF['vehicle_class']=='electric']['kwh'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average diesel: {DF[DF['vehicle_class']=='diesel']['target_kg_per_km'].mean()}, average hybrid {DF[DF['vehicle_class']=='hybrid']['target_kg_per_km'].mean()}, average electric {DF[DF['vehicle_class']=='electric']['target_kg_per_km'].mean()}\")\n",
    "print(f\"median diesel: {DF[DF['vehicle_class']=='diesel']['target_kg_per_km'].median()}, median hybrid {DF[DF['vehicle_class']=='hybrid']['target_kg_per_km'].median()}, median electric {DF[DF['vehicle_class']=='electric']['target_kg_per_km'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average diesel: {DF[DF['vehicle_class']=='diesel']['target_kg'].mean()}, average hybrid {DF[DF['vehicle_class']=='hybrid']['target_kg'].mean()}, average electric {DF[DF['vehicle_class']=='electric']['target_kg'].mean()}\")\n",
    "print(f\"median diesel: {DF[DF['vehicle_class']=='diesel']['target_kg'].median()}, median hybrid {DF[DF['vehicle_class']=='hybrid']['target_kg'].median()}, median electric {DF[DF['vehicle_class']=='electric']['target_kg'].median()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate boxplot values\n",
    "result = {}\n",
    "quantiles = [0.01, 0.25, 0.5, 0.75, 0.99]\n",
    "for vehicle_type in DF['vehicle_class'].unique():\n",
    "    result[f\"ecr_{vehicle_type}\"] = DF[DF['vehicle_class']==vehicle_type]['target_kg_per_km'].quantile(quantiles).tolist()\n",
    "    result[f\"ec_{vehicle_type}\"] = DF[DF['vehicle_class']==vehicle_type]['target_kg'].quantile(quantiles).tolist()\n",
    "    result[f\"energy_{vehicle_type}\"] = DF[DF['vehicle_class']==vehicle_type]['kwh'].quantile(quantiles).tolist()\n",
    "df_results = pd.DataFrame(result)\n",
    "out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", \"energy_boxplot.csv\")\n",
    "df_results.to_csv(out_path, index=False)\n",
    "df_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_cols = ['precipitation_intensity', 'temperature', 'humidity', 'wind_speed', 'wind_gust', 'visibility', 'speed_meters_per_second', 'sr_ave_segment', 'jf_ave_segment', 'sr_ave_trip', 'jf_ave_trip', 'elevation_diff', 'elevation_change', 'distance_travelled_m']\n",
    "feature_cols = ['precipitation_intensity', 'temperature', 'humidity', 'wind_speed', 'wind_gust', 'visibility', 'time_to_travel', 'sr_ave_trip', 'jf_ave_trip', 'elevation_diff', 'actual_elevation_change', 'distance_travelled_m', 'ave_speed']\n",
    "target = 'target_kg_per_km'\n",
    "\n",
    "vehicle_types = DF['vehicle_class'].unique().tolist()\n",
    "column_names = vehicle_types\n",
    "results = []\n",
    "index = []\n",
    "\n",
    "for feature_col in feature_cols:\n",
    "    result = []\n",
    "    for vehicle_type in vehicle_types:\n",
    "        c, p = stats.pearsonr(DF[DF['vehicle_class']==vehicle_type][feature_col], DF[DF['vehicle_class']==vehicle_type][target])\n",
    "        result.append(c)\n",
    "        #result.append(p)\n",
    "    results.append(result)\n",
    "    index.append(feature_col)\n",
    "    \n",
    "df_results = pd.DataFrame(results, index=index, columns=column_names)\n",
    "#df_results.columns = ['ICEV', 'HV', 'EV']\n",
    "df_results = df_results.sort_values(by=['diesel'])\n",
    "df_results = df_results.round(3)\n",
    "out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", \"ecr_correlation2.csv\")\n",
    "df_results.to_csv(out_path, index=True)\n",
    "df_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_cols = ['precipitation_intensity', 'temperature', 'humidity', 'wind_speed', 'wind_gust', 'visibility', 'speed_meters_per_second', 'sr_ave_segment', 'jf_ave_segment', 'sr_ave_trip', 'jf_ave_trip', 'elevation_diff', 'elevation_change', 'distance_travelled_m']\n",
    "target = 'target_kg'\n",
    "\n",
    "vehicle_types = DF['vehicle_class'].unique().tolist()\n",
    "column_names = vehicle_types\n",
    "results = []\n",
    "index = []\n",
    "\n",
    "for feature_col in feature_cols:\n",
    "    result = []\n",
    "    for vehicle_type in vehicle_types:\n",
    "        c, p = stats.pearsonr(DF[DF['vehicle_class']==vehicle_type][feature_col], DF[DF['vehicle_class']==vehicle_type][target])\n",
    "        result.append(c)\n",
    "        #result.append(p)\n",
    "    results.append(result)\n",
    "    index.append(feature_col)\n",
    "    \n",
    "df_results = pd.DataFrame(results, index=index, columns=column_names)\n",
    "#df_results.columns = ['ICEV', 'HV', 'EV']\n",
    "df_results = df_results.sort_values(by=['diesel'])\n",
    "df_results = df_results.round(7)\n",
    "out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", \"ec_correlation2.csv\")\n",
    "df_results.to_csv(out_path, index=True)\n",
    "df_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF.drop(columns=['ave_speed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-piece",
   "metadata": {},
   "source": [
    "## Format Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behavioral-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, val_set=False, random_state=102):\n",
    "    if val_set is True:\n",
    "        df_train = df.sample(frac=0.8, random_state=random_state)\n",
    "        df_test = df.drop(df_train.index)\n",
    "        df_val = df_train.sample(frac=0.1, random_state=random_state)\n",
    "        df_train = df_train.drop(df_val.index)\n",
    "        return df_train, df_val, df_test\n",
    "    else:\n",
    "        df_train = df.sample(frac=0.8, random_state=random_state)\n",
    "        df_test = df.drop(df_train.index)\n",
    "        return df_train, df_test\n",
    "    \n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        \"\"\"\n",
    "        features and labels should be pandas dataframes\n",
    "        \"\"\"\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = np.array(self.features.iloc[idx])\n",
    "        labels = self.labels.iloc[idx]\n",
    "        sample = {'features': features, 'labels': labels}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hungry-arabic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110199, 198070, 42144]\n",
      "diesel_train: len features: 30343, len target: 30343\n",
      "diesel_val: len features: 3372, len target: 3372\n",
      "diesel_test: len features: 8429, len target: 8429\n",
      "hybrid_train: len features: 30343, len target: 30343\n",
      "hybrid_val: len features: 3372, len target: 3372\n",
      "hybrid_test: len features: 8429, len target: 8429\n",
      "electric_train: len features: 30343, len target: 30343\n",
      "electric_val: len features: 3372, len target: 3372\n",
      "electric_test: len features: 8429, len target: 8429\n"
     ]
    }
   ],
   "source": [
    "df_diesel = DF[DF['vehicle_class']=='diesel']\n",
    "df_hybrid = DF[DF['vehicle_class']=='hybrid']\n",
    "df_electric = DF[DF['vehicle_class']=='electric']\n",
    "total_samples = min([len(df_diesel), len(df_hybrid), len(df_electric)])\n",
    "print([len(df_diesel), len(df_hybrid), len(df_electric)])\n",
    "# get datasets\n",
    "datasets = {}\n",
    "\n",
    "temp = df_diesel.sample(n=total_samples, random_state=102).reset_index()\n",
    "train, val, test = train_val_test_split(temp, val_set=True, random_state=102)\n",
    "datasets['diesel_train'] = MyDataset(train[FEATURE_COLUMNS], train[TARGET])\n",
    "datasets['diesel_val'] = MyDataset(val[FEATURE_COLUMNS], val[TARGET])\n",
    "datasets['diesel_test'] = MyDataset(test[FEATURE_COLUMNS], test[TARGET])\n",
    "\n",
    "temp = df_hybrid.sample(n=total_samples, random_state=102).reset_index()\n",
    "train, val, test = train_val_test_split(temp, val_set=True, random_state=102)\n",
    "datasets['hybrid_train'] = MyDataset(train[FEATURE_COLUMNS], train[TARGET])\n",
    "datasets['hybrid_val'] = MyDataset(val[FEATURE_COLUMNS], val[TARGET])\n",
    "datasets['hybrid_test'] = MyDataset(test[FEATURE_COLUMNS], test[TARGET])\n",
    "\n",
    "temp = df_electric.sample(n=total_samples, random_state=102).reset_index()\n",
    "train, val, test = train_val_test_split(temp, val_set=True, random_state=102)\n",
    "datasets['electric_train'] = MyDataset(train[FEATURE_COLUMNS], train[TARGET])\n",
    "datasets['electric_val'] = MyDataset(val[FEATURE_COLUMNS], val[TARGET])\n",
    "datasets['electric_test'] = MyDataset(test[FEATURE_COLUMNS], test[TARGET])\n",
    "\n",
    "for k, v in datasets.items():\n",
    "    print(f\"{k}: len features: {len(v.features)}, len target: {len(v.labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-mother",
   "metadata": {},
   "source": [
    "## 2. MTL Model - parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "professional-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='modelcheckpoint.pt'):\n",
    "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
    "    if is_best:\n",
    "        #print (\"=> Saving a new best\")\n",
    "        torch.save(state, filename)  # save checkpoint\n",
    "    else:\n",
    "        #print (\"=> Validation Accuracy did not improve\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "located-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskModel(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_feature,\n",
    "                 n_shared_width,\n",
    "                 n_shared_depth, \n",
    "                 n_task_widths, \n",
    "                 outlayer='linear'):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.n_feature = n_feature\n",
    "        self.n_shared_width = n_shared_width\n",
    "        self.n_shared_depth = n_shared_depth\n",
    "        self.n_task_widths = n_task_widths\n",
    "        self.outlayer = outlayer\n",
    "        #print(self.outlayer)\n",
    "        \n",
    "        self.task = None # should be set to 'hybrid', 'electric', or 'diesel'\n",
    "        \n",
    "        self.s1 = torch.nn.Linear(self.n_feature, self.n_shared_width)\n",
    "        self.s2 = torch.nn.Linear(self.n_shared_width, self.n_shared_width)\n",
    "        self.s3 = torch.nn.Linear(self.n_shared_width, self.n_shared_width)\n",
    "        self.s4 = torch.nn.Linear(self.n_shared_width, self.n_shared_width)\n",
    "        self.s5 = torch.nn.Linear(self.n_shared_width, self.n_shared_width)\n",
    "        self.s6 = torch.nn.Linear(self.n_shared_width, self.n_shared_width)\n",
    "        \n",
    "        self.d1 = torch.nn.Linear(self.n_shared_width, self.n_task_widths[0])\n",
    "        self.d2 = torch.nn.Linear(self.n_task_widths[0], self.n_task_widths[1])\n",
    "        self.d3 = torch.nn.Linear(self.n_task_widths[1], self.n_task_widths[2])\n",
    "        self.dout = torch.nn.Linear(self.n_task_widths[2], 1)\n",
    "        \n",
    "        self.e1 = torch.nn.Linear(self.n_shared_width, self.n_task_widths[0])\n",
    "        self.e2 = torch.nn.Linear(self.n_task_widths[0], self.n_task_widths[1])\n",
    "        self.e3 = torch.nn.Linear(self.n_task_widths[1], self.n_task_widths[2])\n",
    "        self.eout = torch.nn.Linear(self.n_task_widths[2], 1)\n",
    "        \n",
    "        self.h1 = torch.nn.Linear(self.n_shared_width, self.n_task_widths[0])\n",
    "        self.h2 = torch.nn.Linear(self.n_task_widths[0], self.n_task_widths[1])\n",
    "        self.h3 = torch.nn.Linear(self.n_task_widths[1], self.n_task_widths[2])\n",
    "        self.hout = torch.nn.Linear(self.n_task_widths[2], 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # shared layers\n",
    "        x = torch.nn.functional.relu(self.s1(x))\n",
    "        if self.n_shared_depth > 1:\n",
    "            x = torch.nn.functional.relu(self.s2(x))\n",
    "        if self.n_shared_depth > 2:\n",
    "            x = torch.nn.functional.relu(self.s3(x))\n",
    "        if self.n_shared_depth > 3:\n",
    "            x = torch.nn.functional.relu(self.s4(x))\n",
    "        if self.n_shared_depth > 4:\n",
    "            x = torch.nn.functional.relu(self.s5(x))\n",
    "        if self.n_shared_depth > 5:\n",
    "            x = torch.nn.functional.relu(self.s6(x))\n",
    "        \n",
    "        # task specific layers\n",
    "        if self.task == 'diesel':\n",
    "            x = torch.nn.functional.relu(self.d1(x))\n",
    "            x = torch.nn.functional.relu(self.d2(x))\n",
    "            x = torch.nn.functional.relu(self.d3(x))\n",
    "            x = self.dout(x)\n",
    "            if self.outlayer == 'relu':\n",
    "                x = torch.nn.functional.relu(x)\n",
    "        if self.task == 'hybrid':\n",
    "            x = torch.nn.functional.relu(self.h1(x))\n",
    "            x = torch.nn.functional.relu(self.h2(x))\n",
    "            x = torch.nn.functional.relu(self.h3(x))\n",
    "            x = self.hout(x)\n",
    "            if self.outlayer == 'relu':\n",
    "                x = torch.nn.functional.relu(x)\n",
    "        if self.task == 'electric':\n",
    "            x = torch.nn.functional.relu(self.e1(x))\n",
    "            x = torch.nn.functional.relu(self.e2(x))\n",
    "            x = torch.nn.functional.relu(self.e3(x))\n",
    "            x = self.eout(x)\n",
    "        return torch.flatten(x)\n",
    "\n",
    "    \n",
    "def mean_absolute_percentage_error(model, dataset):\n",
    "    features = torch.tensor(dataset.features.values).double().to(device)\n",
    "    y_pred = model(features).cpu().detach().numpy()\n",
    "    y_true = dataset.labels.values\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "\n",
    "def get_loss_multitask(model, dataset, vehicle_type, loss='mse'):\n",
    "    model.task = vehicle_type\n",
    "    if loss == 'mse':\n",
    "        loss_function = torch.nn.MSELoss(reduction='mean')\n",
    "    else:\n",
    "        loss_function = torch.nn.L1Loss(reduction='mean')\n",
    "    features = torch.tensor(dataset.features.values).double().to(device)\n",
    "    labels = torch.tensor(dataset.labels.values).double().to(device)\n",
    "    #features = torch.tensor(dataset.features.values).double()\n",
    "    #labels = torch.tensor(dataset.labels.values).double()\n",
    "    predicts = model(features)\n",
    "    return loss_function(predicts, labels).item()\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "def get_loss_multitask_dataloader(model, dataloader, vehicle_type, loss='mse'):\n",
    "    result = 0\n",
    "    model.task = vehicle_type\n",
    "    import GPUtil\n",
    "    if loss == 'mse':\n",
    "        loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "    elif loss == 'huber':\n",
    "        loss_function = torch.nn.SmoothL1Loss(reduction='sum')\n",
    "    else:\n",
    "        loss_function = torch.nn.L1Loss(reduction='sum')\n",
    "    for idx, batch_data in enumerate(dataloader):\n",
    "        features = batch_data['features'].double().to(device)\n",
    "        labels = batch_data['labels'].double().to(device)\n",
    "        predicts = model(features)\n",
    "        result += float(loss_function(predicts, labels).item())\n",
    "    return result / len(dataloader.dataset)\n",
    "\n",
    "\n",
    "def gpu_memory():\n",
    "    tt = torch.cuda.get_device_properties(0).total_memory\n",
    "    rr = torch.cuda.memory_reserved(0) \n",
    "    aa = torch.cuda.memory_allocated(0)\n",
    "    ff = rr-aa  # free inside reserved\n",
    "    print(ff / 1000000)\n",
    "\n",
    "\n",
    "def train_multitask(datasets, \n",
    "                    n_shared_width,\n",
    "                    n_shared_depth,\n",
    "                    n_task_widths,\n",
    "                    lr, \n",
    "                    batch_size, \n",
    "                    num_epochs, \n",
    "                    device, \n",
    "                    loss_fun='mse', \n",
    "                    test=False, \n",
    "                    stats_at_epoch=10, \n",
    "                    early_stopping=True, \n",
    "                    outlayer='linear', \n",
    "                    early_stop_epochs=1, \n",
    "                    metrics=['mse', 'mae', 'huber'], \n",
    "                    opt='adam', \n",
    "                    filename='modelcheckpoint.pt', \n",
    "                    val_on_train=True):\n",
    "    \n",
    "    # setup dataloaders\n",
    "    diesel_train_dataloader = torch.utils.data.DataLoader(datasets['diesel_train'], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    hybrid_train_dataloader = torch.utils.data.DataLoader(datasets['hybrid_train'], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    electric_train_dataloader = torch.utils.data.DataLoader(datasets['electric_train'], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    if test is False:\n",
    "        diesel_test_dataloader = torch.utils.data.DataLoader(datasets['diesel_val'], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "        hybrid_test_dataloader = torch.utils.data.DataLoader(datasets['hybrid_val'], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "        electric_test_dataloader = torch.utils.data.DataLoader(datasets['electric_val'], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    else:\n",
    "        diesel_test_dataloader = torch.utils.data.DataLoader(datasets['diesel_test'], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "        hybrid_test_dataloader = torch.utils.data.DataLoader(datasets['hybrid_test'], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "        electric_test_dataloader = torch.utils.data.DataLoader(datasets['electric_test'], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    \n",
    "    # setup model\n",
    "    model = MultiTaskModel(len(FEATURE_COLUMNS), n_shared_width, n_shared_depth, n_task_widths, outlayer=outlayer).to(device)\n",
    "    if loss_fun == 'mse':\n",
    "        loss_function = torch.nn.MSELoss(reduction='mean')\n",
    "    elif loss_fun == 'huber':\n",
    "        loss_function = torch.nn.SmoothL1Loss(reduction='mean')\n",
    "    else:\n",
    "        loss_function = torch.nn.L1Loss(reduction='mean')\n",
    "    \n",
    "    if opt == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    model.double()\n",
    "    \n",
    "    # store results\n",
    "    losses = {}\n",
    "    for metric in metrics:\n",
    "        losses[f\"diesel_test_{metric}\"] = []\n",
    "        losses[f\"hybrid_test_{metric}\"] = []\n",
    "        losses[f\"electric_test_{metric}\"] = []\n",
    "    losses['diesel_train_mse'] = []\n",
    "    losses['hybrid_train_mse'] = []\n",
    "    losses['electric_train_mse'] = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for metric in metrics:\n",
    "            losses[f\"diesel_test_{metric}\"].append(get_loss_multitask_dataloader(model, diesel_test_dataloader, 'diesel', loss=metric))\n",
    "            losses[f\"hybrid_test_{metric}\"].append(get_loss_multitask_dataloader(model, hybrid_test_dataloader, 'hybrid', loss=metric))\n",
    "            losses[f\"electric_test_{metric}\"].append(get_loss_multitask_dataloader(model, electric_test_dataloader, 'electric', loss=metric))\n",
    "            \n",
    "        losses[\"diesel_train_mse\"].append(get_loss_multitask_dataloader(model, diesel_train_dataloader, 'diesel', loss='mse'))\n",
    "        losses[\"hybrid_train_mse\"].append(get_loss_multitask_dataloader(model, hybrid_train_dataloader, 'hybrid', loss='mse'))\n",
    "        losses[\"electric_train_mse\"].append(get_loss_multitask_dataloader(model, electric_train_dataloader, 'electric', loss='mse'))\n",
    "\n",
    "    counter = 0\n",
    "    best_loss = losses[f\"diesel_test_{loss_fun}\"][-1] + losses[f\"hybrid_test_{loss_fun}\"][-1] + losses[f\"electric_test_{loss_fun}\"][-1]\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, batch_data in enumerate(zip(diesel_train_dataloader, hybrid_train_dataloader, electric_train_dataloader)):\n",
    "            model.train()\n",
    "            \n",
    "            model.task = 'diesel'\n",
    "            features = batch_data[0]['features'].double().to(device)\n",
    "            labels = batch_data[0]['labels'].double().to(device)\n",
    "            #optimizer.zero_grad()\n",
    "            predicts = model(features)\n",
    "            loss = loss_function(predicts, labels)\n",
    "            loss.backward()\n",
    "            #optimizer.step()\n",
    "            \n",
    "            model.task = 'hybrid'\n",
    "            features = batch_data[1]['features'].double().to(device)\n",
    "            labels = batch_data[1]['labels'].double().to(device)\n",
    "            #optimizer.zero_grad()\n",
    "            predicts = model(features)\n",
    "            loss = loss_function(predicts, labels)\n",
    "            loss.backward()\n",
    "            #optimizer.step()\n",
    "            \n",
    "            model.task = 'electric'\n",
    "            features = batch_data[2]['features'].double().to(device)\n",
    "            labels = batch_data[2]['labels'].double().to(device)\n",
    "            #optimizer.zero_grad()\n",
    "            predicts = model(features)\n",
    "            loss = loss_function(predicts, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        if (epoch % stats_at_epoch == 0):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for metric in metrics:\n",
    "                    losses[f\"diesel_test_{metric}\"].append(get_loss_multitask_dataloader(model, diesel_test_dataloader, 'diesel', loss=metric))\n",
    "                    losses[f\"hybrid_test_{metric}\"].append(get_loss_multitask_dataloader(model, hybrid_test_dataloader, 'hybrid', loss=metric))\n",
    "                    losses[f\"electric_test_{metric}\"].append(get_loss_multitask_dataloader(model, electric_test_dataloader, 'electric', loss=metric))\n",
    "\n",
    "                losses[\"diesel_train_mse\"].append(get_loss_multitask_dataloader(model, diesel_train_dataloader, 'diesel', loss='mse'))\n",
    "                losses[\"hybrid_train_mse\"].append(get_loss_multitask_dataloader(model, hybrid_train_dataloader, 'hybrid', loss='mse'))\n",
    "                losses[\"electric_train_mse\"].append(get_loss_multitask_dataloader(model, electric_train_dataloader, 'electric', loss='mse'))\n",
    "            if val_on_train is False:\n",
    "                new_loss = losses[f\"diesel_test_{loss_fun}\"][-1] + losses[f\"hybrid_test_{loss_fun}\"][-1] + losses[f\"electric_test_{loss_fun}\"][-1]\n",
    "            else:\n",
    "                new_loss = losses[f\"diesel_train_mse\"][-1] + losses[f\"hybrid_train_mse\"][-1] + losses[f\"electric_train_mse\"][-1]\n",
    "            #print(new_loss)\n",
    "            if new_loss > best_loss:\n",
    "                counter += 1\n",
    "            else:\n",
    "                counter = 0\n",
    "                state = {'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}\n",
    "                save_checkpoint(state, True, filename=filename)\n",
    "                best_loss = deepcopy(new_loss)\n",
    "            if (counter >= early_stop_epochs) and (epoch >= 100) and (early_stopping is True):\n",
    "                break\n",
    "        \n",
    "    df_results = pd.DataFrame(losses)\n",
    "    for metric in metrics:\n",
    "        df_results[f\"total_test_{metric}\"] = df_results.apply(lambda row: row[f\"diesel_test_{metric}\"] + row[f\"hybrid_test_{metric}\"] + row[f\"electric_test_{metric}\"], axis=1)\n",
    "    df_results[f\"total_train_mse\"] = df_results.apply(lambda row: row[\"diesel_train_mse\"] + row[\"hybrid_train_mse\"] + row[\"electric_train_mse\"], axis=1)\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return df_results, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "recovered-glasgow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n",
      "finished a model\n"
     ]
    }
   ],
   "source": [
    "# parameter tuning - MTL model\n",
    "        \n",
    "outlayer = 'linear'\n",
    "opt = 'adamw'\n",
    "n_shared_width_list = [200, 300, 400]\n",
    "n_shared_depth_list = [3, 4, 5]\n",
    "n_task_widths = [64, 32, 16]\n",
    "lr_list = [0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "#lr_list = [0.001, 0.0005, 0.0001]\n",
    "batch_size_list = [128, 256, 512]\n",
    "loss_fun_list = ['mse']\n",
    "metrics = ['mse']\n",
    "dropout = 0\n",
    "\n",
    "num_epochs = 150\n",
    "early_stopping = True\n",
    "stats_at_epoch = 1\n",
    "test = False\n",
    "early_stop_epochs = 10\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "results = {'test_mse': [],  \n",
    "           'n_shared_width': [], \n",
    "           'n_shared_depth': [], \n",
    "           'lr': [], \n",
    "           'batch_size': [], \n",
    "           'loss_fun': []}\n",
    "\n",
    "out_path = os.path.join(os.getcwd(), 'output_r', 'latex', 'mtl_gridsearch.csv')\n",
    "\n",
    "for n_shared_width in n_shared_width_list:\n",
    "    for n_shared_depth in n_shared_depth_list:\n",
    "            for lr in lr_list:\n",
    "                for batch_size in batch_size_list:\n",
    "                    for loss_fun in loss_fun_list:\n",
    "                        if os.path.isfile(out_path):\n",
    "                            df_past = pd.read_csv(out_path)\n",
    "                            if len(df_past[(df_past['n_shared_width']==n_shared_width) & (df_past['n_shared_depth']==n_shared_depth) & (df_past['lr']==lr) & (df_past['batch_size']==batch_size) & (df_past['loss_fun']==loss_fun)]) != 0:\n",
    "                                print('continue')\n",
    "                                continue\n",
    "                        else:\n",
    "                            df_past = None\n",
    "                                \n",
    "                        df_results, _ = train_multitask(datasets, \n",
    "                                                        n_shared_width, \n",
    "                                                        n_shared_depth, \n",
    "                                                        n_task_widths, \n",
    "                                                        lr, \n",
    "                                                        batch_size, \n",
    "                                                        num_epochs, \n",
    "                                                        device, \n",
    "                                                        loss_fun=loss_fun, \n",
    "                                                        test=test, \n",
    "                                                        stats_at_epoch=stats_at_epoch, \n",
    "                                                        early_stopping=early_stopping, \n",
    "                                                        outlayer=outlayer, \n",
    "                                                        early_stop_epochs=early_stop_epochs, \n",
    "                                                        metrics=metrics, \n",
    "                                                        opt=opt)\n",
    "                            \n",
    "                        results['test_mse'].append(df_results['total_test_mse'].min())\n",
    "                        results['n_shared_width'].append(n_shared_width)\n",
    "                        results['n_shared_depth'].append(n_shared_depth)\n",
    "                        results['lr'].append(lr)\n",
    "                        results['batch_size'].append(batch_size)\n",
    "                        results['loss_fun'].append(loss_fun)\n",
    "                            \n",
    "                        df_new = pd.DataFrame(results)\n",
    "                        if df_past is not None:\n",
    "                            df_new = pd.concat([df_past, df_new], ignore_index=True)\n",
    "                            df_new = df_new.drop_duplicates(subset=['n_shared_width', 'n_shared_depth', 'lr', 'batch_size', 'loss_fun'])\n",
    "                        df_new.to_csv(out_path, index=False)\n",
    "                        print('finished a model')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-production",
   "metadata": {},
   "source": [
    "## 3. Baseline Model - parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "solid-marketing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 n_feature,\n",
    "                 n_hidden,\n",
    "                 n_output,\n",
    "                 dropout,\n",
    "                 n_layers):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.n_feature = n_feature\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        self.dropout = dropout\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.f1 = torch.nn.Linear(self.n_feature, self.n_hidden)\n",
    "        self.f2 = torch.nn.Linear(self.n_hidden, self.n_hidden)\n",
    "        self.f3 = torch.nn.Linear(self.n_hidden, self.n_hidden)\n",
    "        self.f4 = torch.nn.Linear(self.n_hidden, self.n_hidden)\n",
    "        self.f5 = torch.nn.Linear(self.n_hidden, self.n_hidden)\n",
    "        self.f6 = torch.nn.Linear(self.n_hidden, self.n_hidden)\n",
    "        #self.out = torch.nn.Linear(self.n_hidden, self.n_output)\n",
    "        \n",
    "        self.v1 = torch.nn.Linear(self.n_hidden, 64)\n",
    "        self.v2 = torch.nn.Linear(64, 32)\n",
    "        self.v3 = torch.nn.Linear(32, 16)\n",
    "        self.out = torch.nn.Linear(16, self.n_output)\n",
    "    \n",
    "    def feature_extractor(self, x):\n",
    "        x = torch.nn.functional.relu(self.f1(x))\n",
    "        x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        if self.n_layers > 1:\n",
    "            x = torch.nn.functional.relu(self.f2(x))\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        if self.n_layers > 2:\n",
    "            x = torch.nn.functional.relu(self.f3(x))\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        if self.n_layers > 3:\n",
    "            x = torch.nn.functional.relu(self.f4(x))\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        if self.n_layers > 4:\n",
    "            x = torch.nn.functional.relu(self.f5(x))\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        if self.n_layers > 5:\n",
    "            x = torch.nn.functional.relu(self.f6(x))\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "    \n",
    "    def regressor(self, x):\n",
    "        x = torch.nn.functional.relu(self.v1(x))\n",
    "        x = torch.nn.functional.relu(self.v2(x))\n",
    "        x = torch.nn.functional.relu(self.v3(x))\n",
    "        x = self.out(x)   \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.regressor(x)\n",
    "        return torch.flatten(x)\n",
    "    \n",
    "    def forwardVoid(self, x):\n",
    "        x = torch.nn.functional.relu(self.f1(x))\n",
    "        x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        if self.n_layers > 1:\n",
    "            x = torch.nn.functional.relu(self.f2(x))\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        if self.n_layers > 2:\n",
    "            x = torch.nn.functional.relu(self.f3(x))\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        if self.n_layers > 3:\n",
    "            x = torch.nn.functional.relu(self.f4(x))\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        if self.n_layers > 4:\n",
    "            x = torch.nn.functional.relu(self.f5(x))\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        if self.n_layers > 5:\n",
    "            x = torch.nn.functional.relu(self.f6(x))\n",
    "            x = torch.nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        x = torch.nn.functional.relu(self.v1(x))\n",
    "        x = torch.nn.functional.relu(self.v2(x))\n",
    "        x = torch.nn.functional.relu(self.v3(x))\n",
    "        x = self.out(x)         \n",
    "        return torch.flatten(x)\n",
    "    \n",
    "\n",
    "def get_loss_baseline_dataloader(model, dataloader, loss='mse'):\n",
    "    result = 0\n",
    "    if loss == 'mse':\n",
    "        loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "    elif loss == 'huber':\n",
    "        loss_function = torch.nn.SmoothL1Loss(reduction='sum')\n",
    "    else:\n",
    "        loss_function = torch.nn.L1Loss(reduction='sum')\n",
    "    for idx, batch_data in enumerate(dataloader):\n",
    "        features = batch_data['features'].double().to(device)\n",
    "        labels = batch_data['labels'].double().to(device)\n",
    "        predicts = model(features)\n",
    "        result += float(loss_function(predicts, labels).item())\n",
    "    return result / len(dataloader.dataset)\n",
    "    \n",
    "    \n",
    "def train_baseline(datasets,\n",
    "                   vehicle_class,\n",
    "                   n_hidden, \n",
    "                   n_layers, \n",
    "                   lr, \n",
    "                   batch_size, \n",
    "                   num_epochs, \n",
    "                   device, \n",
    "                   dropout=0,\n",
    "                   test=False, \n",
    "                   stats_at_epoch=10, \n",
    "                   early_stopping=True, \n",
    "                   early_stop_epochs=1, \n",
    "                   metrics=['mse', 'mae', 'huber'], \n",
    "                   loss_fun='mse', \n",
    "                   filename='modelcheckpoint.pt', \n",
    "                   val_on_train=True, \n",
    "                   opt='adam', \n",
    "                   model=None, \n",
    "                   optimizer=None):\n",
    "    # setup dataloaders\n",
    "    train_dataloader = torch.utils.data.DataLoader(datasets[f\"{vehicle_class}_train\"], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    if test is True:\n",
    "        test_dataloader = torch.utils.data.DataLoader(datasets[f\"{vehicle_class}_test\"], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    else:\n",
    "        test_dataloader = torch.utils.data.DataLoader(datasets[f\"{vehicle_class}_val\"], batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "    \n",
    "    # setup model\n",
    "    if model is None:\n",
    "        model = BaselineModel(len(FEATURE_COLUMNS), n_hidden, 1, dropout, n_layers).to(device)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    \n",
    "    if optimizer is None:\n",
    "        if opt == 'adam':\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    model.double()\n",
    "    \n",
    "    # store results\n",
    "    losses = {}\n",
    "    for metric in metrics:\n",
    "        losses[f\"test_{metric}\"] = []\n",
    "    losses[\"train_mse\"] = []\n",
    "    \n",
    "    # get initial loss\n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for metric in metrics:\n",
    "            losses[f\"test_{metric}\"].append(get_loss_baseline_dataloader(model, test_dataloader, loss=metric))\n",
    "    losses[\"train_mse\"].append(get_loss_baseline_dataloader(model, train_dataloader, loss='mse'))\n",
    "    best_loss = losses[f\"test_{loss_fun}\"][-1]\n",
    "    \n",
    "    # train\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for idx, batch_data in enumerate(train_dataloader):\n",
    "            features = batch_data['features'].double().to(device)\n",
    "            labels = batch_data['labels'].double().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            predicts = model(features)\n",
    "            loss = loss_function(predicts, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if (epoch % stats_at_epoch == 0):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for metric in metrics:\n",
    "                    losses[f\"test_{metric}\"].append(get_loss_baseline_dataloader(model, test_dataloader, loss=metric))\n",
    "                losses[\"train_mse\"].append(get_loss_baseline_dataloader(model, train_dataloader, loss='mse'))\n",
    "\n",
    "            if val_on_train is False:\n",
    "                new_loss = losses[f\"test_{loss_fun}\"][-1] \n",
    "            else:\n",
    "                new_loss = losses[\"train_mse\"][-1] \n",
    "                \n",
    "            if new_loss > best_loss:\n",
    "                counter += 1\n",
    "            else:\n",
    "                counter = 0\n",
    "                state = {'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}\n",
    "                save_checkpoint(state, True, filename=filename)\n",
    "                best_loss = deepcopy(new_loss)\n",
    "            if (counter >= early_stop_epochs) and (epoch >= 75) and (early_stopping is True):\n",
    "                break\n",
    "    df_results = pd.DataFrame(losses)\n",
    "    \n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return df_results, model\n",
    "\n",
    "\n",
    "def train_baseline_allclasses(datasets,\n",
    "                              n_hidden, \n",
    "                              n_layers, \n",
    "                              lr, \n",
    "                              batch_size, \n",
    "                              num_epochs, \n",
    "                              device, \n",
    "                              dropout=0,\n",
    "                              test=False,\n",
    "                              vehicle_class_list=['diesel', 'hybrid', 'electric'],\n",
    "                              stats_at_epoch=10, \n",
    "                              early_stopping=True, \n",
    "                              early_stop_epochs=1, \n",
    "                              metrics=['mse', 'mae', 'huber'], \n",
    "                              loss_fun='mse', \n",
    "                              filename='baseline.pt', \n",
    "                              val_on_train=True, \n",
    "                              opt='adam'):\n",
    "    # store results\n",
    "    losses = {}\n",
    "    for metric in metrics:\n",
    "        for vehicle_class in vehicle_class_list:\n",
    "            losses[f\"{vehicle_class}_test_{metric}\"] = []\n",
    "    for vehicle_class in vehicle_class_list:\n",
    "        losses[f\"{vehicle_class}_train_mse\"] = []\n",
    "    \n",
    "    # train and store results\n",
    "    models = {}\n",
    "    for vehicle_class in vehicle_class_list:\n",
    "        df_result, model = train_baseline(datasets, \n",
    "                                          vehicle_class, \n",
    "                                          n_hidden, \n",
    "                                          n_layers, \n",
    "                                          lr, \n",
    "                                          batch_size, \n",
    "                                          num_epochs, \n",
    "                                          device, \n",
    "                                          dropout=0, \n",
    "                                          test=test, \n",
    "                                          stats_at_epoch=stats_at_epoch, \n",
    "                                          early_stopping=early_stopping, \n",
    "                                          early_stop_epochs=early_stop_epochs, \n",
    "                                          metrics=metrics, \n",
    "                                          loss_fun=loss_fun, \n",
    "                                          filename=filename, \n",
    "                                          val_on_train=val_on_train, \n",
    "                                          opt=opt)\n",
    "        models[vehicle_class] = deepcopy(model)\n",
    "        for metric in metrics:\n",
    "            losses[f\"{vehicle_class}_test_{metric}\"] = df_result[f\"test_{metric}\"]\n",
    "        losses[f\"{vehicle_class}_train_mse\"] = df_result[\"train_mse\"]\n",
    "    \n",
    "    # add total values to result\n",
    "    df_results = pd.DataFrame(losses)\n",
    "    for metric in metrics:\n",
    "         df_results[f\"total_test_{metric}\"] = df_results.apply(lambda row: row[f\"diesel_test_{metric}\"] + row[f\"hybrid_test_{metric}\"] + row[f\"electric_test_{metric}\"], axis=1)\n",
    "    df_results[f\"total_train_mse\"] = df_results.apply(lambda row: row[f\"diesel_train_mse\"] + row[f\"hybrid_train_mse\"] + row[f\"electric_train_mse\"], axis=1)\n",
    "    return df_results, models\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-listening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n",
      "Done with a model\n"
     ]
    }
   ],
   "source": [
    "# Baseline hyper parameter turning\n",
    "\n",
    "n_hidden_list = [300, 400, 500]\n",
    "n_layers_list = [3, 4, 5]\n",
    "#lr_list = [0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
    "lr_list = [0.001, 0.0005, 0.0001]\n",
    "batch_size_list = [128, 256, 512]\n",
    "\n",
    "num_epochs = 50\n",
    "early_stopping = True\n",
    "stats_at_epoch = 1\n",
    "test = False\n",
    "early_stop_epochs = 10\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda:1')\n",
    "metrics = ['mse']\n",
    "loss_function = 'mse'\n",
    "\n",
    "results = {'test_mse': [],\n",
    "           'diesel_test_mse': [],\n",
    "           'hybrid_test_mse': [],\n",
    "           'electric_test_mse': [],\n",
    "           'n_hidden': [], \n",
    "           'n_layers': [], \n",
    "           'lr': [], \n",
    "           'batch_size': []}\n",
    "\n",
    "out_path = os.path.join(os.getcwd(), 'output_r', 'latex', 'baseline_gridsearch.csv')\n",
    "\n",
    "for n_hidden in n_hidden_list:\n",
    "    for n_layers in n_layers_list:\n",
    "        for lr in lr_list:\n",
    "            for batch_size in batch_size_list:\n",
    "                if os.path.isfile(out_path):\n",
    "                    df_past = pd.read_csv(out_path)\n",
    "                    if len(df_past[(df_past['n_hidden']==n_hidden) & (df_past['n_layers']==n_layers) & (df_past['lr']==lr) & (df_past['batch_size']==batch_size)]) != 0:\n",
    "                        print('continue')\n",
    "                        continue\n",
    "                else:\n",
    "                    df_past = None\n",
    "                \n",
    "                df_results, models = train_baseline_allclasses(datasets, \n",
    "                                                       n_hidden, \n",
    "                                                       n_layers, \n",
    "                                                       lr, \n",
    "                                                       batch_size, \n",
    "                                                       num_epochs, \n",
    "                                                       device, \n",
    "                                                       dropout=0, \n",
    "                                                       test=test, \n",
    "                                                       stats_at_epoch=stats_at_epoch, \n",
    "                                                       early_stopping=early_stopping, \n",
    "                                                       early_stop_epochs=early_stop_epochs, \n",
    "                                                       metrics=metrics, \n",
    "                                                       loss_fun=loss_function)\n",
    "                #results['test_huber'].append(df_results['total_test_huber'].min())\n",
    "                results['test_mse'].append(df_results['total_test_mse'].min())\n",
    "                results['diesel_test_mse'].append(df_results['diesel_test_mse'].min())\n",
    "                results['hybrid_test_mse'].append(df_results['hybrid_test_mse'].min())\n",
    "                results['electric_test_mse'].append(df_results['electric_test_mse'].min())\n",
    "                results['n_hidden'].append(n_hidden)\n",
    "                results['n_layers'].append(n_layers)\n",
    "                results['lr'].append(lr)\n",
    "                results['batch_size'].append(batch_size)\n",
    "            \n",
    "                df_new = pd.DataFrame(results)\n",
    "                if df_past is not None:\n",
    "                    df_new = pd.concat([df_past, df_new], ignore_index=True)\n",
    "                    df_new = df_new.drop_duplicates()\n",
    "                df_new.to_csv(out_path, index=False)\n",
    "                print(\"Done with a model\")\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-fleece",
   "metadata": {},
   "source": [
    "## 4. MTL vs Baseline\n",
    "\n",
    "This section outputs the results for Section 4.2 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_params = {'loss_fun': 'mse', 'outlayer': 'linear', 'n_shared_width': 300, 'n_shared_depth': 5, 'n_task_widths': [64, 32, 16], 'lr': 0.0005, 'batch_size': 256, 'opt': 'adamw', 'filename': os.path.join(os.getcwd(), 'models', 'mtlvsbaselinemtl.pt')}\n",
    "baseline_params = {'loss_fun': 'mse', 'n_hidden': 300, 'n_layers': 5, 'lr': 0.0005, 'batch_size': 256, 'filename': os.path.join(os.getcwd(), 'models', 'mtlvsbaselinebaseline.pt')}\n",
    "\n",
    "num_epochs = 150\n",
    "device = torch.device('cuda:1')\n",
    "test = True\n",
    "stats_at_epoch = 1\n",
    "early_stopping = False\n",
    "early_stop_epochs = 10\n",
    "dropout = 0\n",
    "number_of_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train multitask\n",
    "results = {}\n",
    "\n",
    "losses = {'diesel_test_mse': [], \n",
    "          'hybrid_test_mse': [], \n",
    "          'electric_test_mse': [], \n",
    "          'diesel_test_mae': [], \n",
    "          'hybrid_test_mae': [], \n",
    "          'electric_test_mae': [],\n",
    "          'diesel_test_huber': [], \n",
    "          'hybrid_test_huber': [], \n",
    "          'electric_test_huber': []}\n",
    "\n",
    "for run in range(number_of_runs):\n",
    "    start_time = time.time()\n",
    "    df_results, model = train_multitask(datasets, \n",
    "                                        mtl_params['n_shared_width'], \n",
    "                                        mtl_params['n_shared_depth'], \n",
    "                                        mtl_params['n_task_widths'],\n",
    "                                        mtl_params['lr'], \n",
    "                                        mtl_params['batch_size'], \n",
    "                                        num_epochs, \n",
    "                                        device, \n",
    "                                        loss_fun=mtl_params['loss_fun'], \n",
    "                                        test=test, \n",
    "                                        stats_at_epoch=stats_at_epoch, \n",
    "                                        early_stopping=early_stopping, \n",
    "                                        outlayer=mtl_params['outlayer'], \n",
    "                                        early_stop_epochs=early_stop_epochs, \n",
    "                                        metrics=['mse', 'mae', 'huber'], \n",
    "                                        opt=mtl_params['opt'], \n",
    "                                        filename=mtl_params['filename'], \n",
    "                                        val_on_train=True)\n",
    "    \n",
    "    ind = df_results[['total_test_huber']].idxmin()['total_test_huber']\n",
    "    for k in losses.keys():\n",
    "        losses[k].append(df_results.iloc[ind][k])\n",
    "    print(time.time() - start_time)\n",
    "    \n",
    "out_path = os.path.join(os.getcwd(), 'output_r', 'latex', 'mtltrainingloss.csv')\n",
    "df_results.to_csv(out_path, index_label='epoch')\n",
    "\n",
    "temp = pd.DataFrame(losses)\n",
    "temp['total_test_huber'] = temp.apply(lambda row: row['diesel_test_huber'] + row['hybrid_test_huber'] + row['electric_test_huber'], axis=1)\n",
    "temp['total_test_mse'] = temp.apply(lambda row: row['diesel_test_mse'] + row['hybrid_test_mse'] + row['electric_test_mse'], axis=1)\n",
    "temp['total_test_mae'] = temp.apply(lambda row: row['diesel_test_mae'] + row['hybrid_test_mae'] + row['electric_test_mae'], axis=1)\n",
    "results['mtl_mean'] = temp.mean(axis=0)\n",
    "results['mtl_median'] = temp.median(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'diesel_test_mse': [], \n",
    "          'hybrid_test_mse': [], \n",
    "          'electric_test_mse': [], \n",
    "          'diesel_test_mae': [], \n",
    "          'hybrid_test_mae': [], \n",
    "          'electric_test_mae': [],\n",
    "          'diesel_test_huber': [], \n",
    "          'hybrid_test_huber': [], \n",
    "          'electric_test_huber': []}\n",
    "\n",
    "for run in range(number_of_runs):\n",
    "    start_time = time.time()\n",
    "    df_results, models = train_baseline_allclasses(datasets, \n",
    "                                                   baseline_params['n_hidden'], \n",
    "                                                   baseline_params['n_layers'], \n",
    "                                                   baseline_params['lr'], \n",
    "                                                   baseline_params['batch_size'], \n",
    "                                                   num_epochs, \n",
    "                                                   device, \n",
    "                                                   dropout=0, \n",
    "                                                   test=test, \n",
    "                                                   stats_at_epoch=stats_at_epoch, \n",
    "                                                   early_stopping=early_stopping, \n",
    "                                                   early_stop_epochs=early_stop_epochs, \n",
    "                                                   metrics=['mse', 'mae', 'huber'], \n",
    "                                                   loss_fun='mse', \n",
    "                                                   filename=baseline_params['filename'])\n",
    "    \n",
    "    ind = df_results[['total_test_mse']].idxmin()['total_test_mse']\n",
    "    for k in losses.keys():\n",
    "        losses[k].append(df_results.iloc[ind][k])\n",
    "        \n",
    "    #for k in losses.keys():\n",
    "    #    losses[k].append(df_results[k].min())\n",
    "    print(time.time() - start_time)\n",
    "    \n",
    "out_path = os.path.join(os.getcwd(), 'output_r', 'latex', 'baselinetrainingloss.csv')\n",
    "df_results.to_csv(out_path, index_label='epoch')\n",
    "\n",
    "temp = pd.DataFrame(losses)\n",
    "temp['total_test_huber'] = temp.apply(lambda row: row['diesel_test_huber'] + row['hybrid_test_huber'] + row['electric_test_huber'], axis=1)\n",
    "temp['total_test_mse'] = temp.apply(lambda row: row['diesel_test_mse'] + row['hybrid_test_mse'] + row['electric_test_mse'], axis=1)\n",
    "temp['total_test_mae'] = temp.apply(lambda row: row['diesel_test_mae'] + row['hybrid_test_mae'] + row['electric_test_mae'], axis=1)\n",
    "results['baseline_mean'] = temp.mean(axis=0)\n",
    "results['baseline_median'] = temp.median(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(results)\n",
    "out_path = os.path.join(os.getcwd(), 'output_r', 'latex', 'mtl_vs_baseline.csv')\n",
    "temp.to_csv(out_path, index_label='description')\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(os.path.join(os.getcwd(), 'output_r', 'latex', 'mtl_vs_baseline.csv'))\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-crystal",
   "metadata": {},
   "source": [
    "## 6. Bootstrap\n",
    "\n",
    "This section corresponds to the MTL bootstrap evaluation in Section 4.2.\n",
    "\n",
    "* split datasets into Tbv and Ubv\n",
    "* train model\n",
    "* predict on Ubv\n",
    "* join results with previous runs\n",
    "\n",
    "returns\n",
    "* index, predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_split(df, frac=1.0, random_state=None, replace=True):\n",
    "    if random_state is None:\n",
    "        df_train = df.sample(frac=frac, replace=replace)\n",
    "    else:\n",
    "        df_train = df.sample(frac=frac, replace=replace, random_state=random_state)\n",
    "    df_test = df[~df.index.isin(df_train.index.unique())]\n",
    "    return df_train, df_test\n",
    "\n",
    "\n",
    "def get_bias(df, result):\n",
    "    biases = []\n",
    "    for k, v in df.iterrows():\n",
    "        y_true = v[TARGET]\n",
    "        y_preds = []\n",
    "        for sim in result:\n",
    "            try:\n",
    "                y_preds.append(sim.loc[k])\n",
    "            except:\n",
    "                continue\n",
    "        if len(y_preds) > 0:\n",
    "            bias = np.abs(np.mean(y_preds) - y_true)\n",
    "            biases.append(bias)\n",
    "    return np.mean(biases), biases\n",
    "\n",
    "\n",
    "def prepare_bootstrap_data(data, frac=1.0, replace=True):\n",
    "    df_train_diesel, df_test_diesel = bootstrap_split(data['diesel'], frac=frac, replace=replace)\n",
    "    df_train_hybrid, df_test_hybrid = bootstrap_split(data['hybrid'], frac=frac, replace=replace)\n",
    "    df_train_electric, df_test_electric = bootstrap_split(data['electric'], frac=frac, replace=replace)\n",
    "    \n",
    "    datasets2 = {}\n",
    "    datasets2['diesel_train'] = MyDataset(df_train_diesel[FEATURE_COLUMNS], df_train_diesel[TARGET])\n",
    "    datasets2['diesel_test'] = MyDataset(df_test_diesel[FEATURE_COLUMNS], df_test_diesel[TARGET])\n",
    "    datasets2['hybrid_train'] = MyDataset(df_train_hybrid[FEATURE_COLUMNS], df_train_hybrid[TARGET])\n",
    "    datasets2['hybrid_test'] = MyDataset(df_test_hybrid[FEATURE_COLUMNS], df_test_hybrid[TARGET])\n",
    "    datasets2['electric_train'] = MyDataset(df_train_electric[FEATURE_COLUMNS], df_train_electric[TARGET])\n",
    "    datasets2['electric_test'] = MyDataset(df_test_electric[FEATURE_COLUMNS], df_test_electric[TARGET])\n",
    "    \n",
    "    datas = {'df_train_diesel': df_train_diesel, \n",
    "             'df_test_diesel': df_test_diesel, \n",
    "             'df_train_hybrid': df_train_hybrid, \n",
    "             'df_test_hybrid': df_test_hybrid, \n",
    "             'df_train_electric': df_train_electric, \n",
    "             'df_test_electric': df_test_electric}\n",
    "    return datasets2, datas\n",
    "\n",
    "\n",
    "def run_bootstrap_baseline_interation(datasets,\n",
    "                                      datas,\n",
    "                                      params, \n",
    "                                      device, \n",
    "                                      num_epochs=300, \n",
    "                                      early_stopping=False, \n",
    "                                      early_stop_epochs=1000, \n",
    "                                      stats_at_epoch=1, \n",
    "                                      frac=1.0):\n",
    "    df_results, models = train_baseline_allclasses(datasets,\n",
    "                                                   params['n_hidden'], \n",
    "                                                   params['n_layers'], \n",
    "                                                   params['lr'], \n",
    "                                                   params['batch_size'], \n",
    "                                                   num_epochs, \n",
    "                                                   device, \n",
    "                                                   dropout=0,\n",
    "                                                   test=True,\n",
    "                                                   vehicle_class_list=['diesel', 'hybrid', 'electric'],\n",
    "                                                   stats_at_epoch=stats_at_epoch, \n",
    "                                                   early_stopping=early_stopping, \n",
    "                                                   early_stop_epochs=early_stop_epochs, \n",
    "                                                   metrics=[params['loss_fun']], \n",
    "                                                   loss_fun=params['loss_fun'], filename=params['filename'], val_on_train=False)\n",
    "    models['diesel'].eval()\n",
    "    models['hybrid'].eval()\n",
    "    models['electric'].eval()\n",
    "    with torch.no_grad():\n",
    "        # predict values diesel\n",
    "        features = torch.tensor(datas['df_test_diesel'][FEATURE_COLUMNS].values).double().to(device)\n",
    "        predicts = models['diesel'](features).cpu().detach().numpy()\n",
    "        result_diesel = pd.Series(data=predicts, index=datas['df_test_diesel'].index)\n",
    "    \n",
    "        # predict values hybrid\n",
    "        features = torch.tensor(datas['df_test_hybrid'][FEATURE_COLUMNS].values).double().to(device)\n",
    "        predicts = models['hybrid'](features).cpu().detach().numpy()\n",
    "        result_hybrid = pd.Series(data=predicts, index=datas['df_test_hybrid'].index)\n",
    "    \n",
    "        # predict values electric\n",
    "        features = torch.tensor(datas['df_test_electric'][FEATURE_COLUMNS].values).double().to(device)\n",
    "        predicts = models['electric'](features).cpu().detach().numpy()\n",
    "        result_electric = pd.Series(data=predicts, index=datas['df_test_electric'].index)\n",
    "    \n",
    "    return result_diesel, result_hybrid, result_electric\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def run_bootstrap_multitask_interation(datasets, \n",
    "                                       datas,\n",
    "                                       mtl_params, \n",
    "                                       device, \n",
    "                                       num_epochs=300, \n",
    "                                       early_stopping=False, \n",
    "                                       early_stop_epochs=1000, \n",
    "                                       stats_at_epoch=1):\n",
    "    df_results, mtl_model = train_multitask(datasets, \n",
    "                                            mtl_params['n_shared_width'], \n",
    "                                            mtl_params['n_shared_depth'], \n",
    "                                            mtl_params['n_task_widths'], \n",
    "                                            mtl_params['lr'], \n",
    "                                            mtl_params['batch_size'], \n",
    "                                            num_epochs, device, \n",
    "                                            loss_fun=mtl_params['loss_fun'], \n",
    "                                            test=True, \n",
    "                                            stats_at_epoch=stats_at_epoch, \n",
    "                                            early_stopping=early_stopping, \n",
    "                                            outlayer=mtl_params['outlayer'], \n",
    "                                            early_stop_epochs=early_stop_epochs, \n",
    "                                            metrics=[mtl_params['loss_fun']], \n",
    "                                            opt=mtl_params['opt'], filename=mtl_params['filename'], val_on_train=False)\n",
    "    mtl_model.eval()\n",
    "    with torch.no_grad():\n",
    "        # predict values diesel\n",
    "        features = torch.tensor(datas['df_test_diesel'][FEATURE_COLUMNS].values).double().to(device)\n",
    "        mtl_model.task = 'diesel'\n",
    "        predicts = mtl_model(features).cpu().detach().numpy()\n",
    "        result_diesel = pd.Series(data=predicts, index=datas['df_test_diesel'].index)\n",
    "    \n",
    "        # predict values hybrid\n",
    "        features = torch.tensor(datas['df_test_hybrid'][FEATURE_COLUMNS].values).double().to(device)\n",
    "        mtl_model.task = 'hybrid'\n",
    "        predicts = mtl_model(features).cpu().detach().numpy()\n",
    "        result_hybrid = pd.Series(data=predicts, index=datas['df_test_hybrid'].index)\n",
    "    \n",
    "        # predict values electric\n",
    "        features = torch.tensor(datas['df_test_electric'][FEATURE_COLUMNS].values).double().to(device)\n",
    "        mtl_model.task = 'electric'\n",
    "        predicts = mtl_model(features).cpu().detach().numpy()\n",
    "        result_electric = pd.Series(data=predicts, index=datas['df_test_electric'].index)\n",
    "    return result_diesel, result_hybrid, result_electric\n",
    "\n",
    "\n",
    "def run_bootstrap(data, \n",
    "                  num_boot_runs, \n",
    "                  device, \n",
    "                  mtl_params, \n",
    "                  baseline_params, \n",
    "                  num_epochs, \n",
    "                  frac=1.0, \n",
    "                  replace=True, \n",
    "                  model_type=['mtl', 'baseline']):\n",
    "    results = {}\n",
    "    if 'mtl' in model_type:\n",
    "        results['mtl_diesel'] = []\n",
    "        results['mtl_hybrid'] = []\n",
    "        results['mtl_electric'] = []\n",
    "    if 'baseline' in model_type:\n",
    "        results['baseline_diesel'] = []\n",
    "        results['baseline_hybrid'] = []\n",
    "        results['baseline_electric'] = []\n",
    "        \n",
    "    for boot_run in range(num_boot_runs):\n",
    "        start_time = time.time()\n",
    "        datasets, datas = prepare_bootstrap_data(data, frac=frac, replace=replace)\n",
    "        if 'mtl' in model_type:\n",
    "            mtl_diesel, mtl_hybrid, mtl_electric = run_bootstrap_multitask_interation(deepcopy(datasets), deepcopy(datas), mtl_params, device, num_epochs=num_epochs)\n",
    "            results['mtl_diesel'].append(mtl_diesel)\n",
    "            results['mtl_hybrid'].append(mtl_hybrid)\n",
    "            results['mtl_electric'].append(mtl_electric)\n",
    "        if 'baseline' in model_type:\n",
    "            baseline_diesel, baseline_hybrid, baseline_electric = run_bootstrap_baseline_interation(deepcopy(datasets), deepcopy(datas), baseline_params, device, num_epochs=num_epochs)\n",
    "            results['baseline_diesel'].append(baseline_diesel)\n",
    "            results['baseline_hybrid'].append(baseline_hybrid)\n",
    "            results['baseline_electric'].append(baseline_electric)\n",
    "        end_time = time.time() - start_time\n",
    "        print(f\"done with boot_run: {boot_run} in {end_time} seconds\")\n",
    "        out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", f\"bootresultstemp2.pkl\")\n",
    "        with open(out_path, 'wb') as handle:\n",
    "            pickle.dump(results, handle)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_ave_mse(data, result):\n",
    "    mses = []\n",
    "    for sim in result:\n",
    "        y_true = data.loc[sim.index, TARGET].values\n",
    "        y_pred = sim.values\n",
    "        mses.append(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "        #maes.append(sklearn.metrics.mean_absolute_error(y_true, y_pred))\n",
    "    return np.mean(mses), mses\n",
    "\n",
    "\n",
    "def get_ave_mae(data, result):\n",
    "    maes = []\n",
    "    for sim in result:\n",
    "        y_true = data.loc[sim.index, TARGET].values\n",
    "        y_pred = sim.values\n",
    "        #mses.append(sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "        maes.append(sklearn.metrics.mean_absolute_error(y_true, y_pred))\n",
    "    return np.mean(maes), maes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_params = {'loss_fun': 'mse', 'outlayer': 'linear', 'n_shared_width': 300, 'n_shared_depth': 5, 'n_task_widths': [64, 32, 16], 'lr': 0.0005, 'batch_size': 256, 'opt': 'adamw', 'filename': os.path.join(os.getcwd(), 'models', 'bootstrapmtl.pt')}\n",
    "baseline_params = {'loss_fun': 'mse', 'n_hidden': 300, 'n_layers': 5, 'lr': 0.0005, 'batch_size': 256, 'filename': os.path.join(os.getcwd(), 'models', 'bootstrapbaseline.pt')}\n",
    "\n",
    "num_boot_runs = 30\n",
    "device = torch.device('cuda:2')\n",
    "num_epochs = 150\n",
    "model_type=['mtl', 'baseline']\n",
    "\n",
    "data = {}\n",
    "for vehicle_class in ['diesel', 'hybrid', 'electric']:\n",
    "    features = pd.concat([datasets[f\"{vehicle_class}_train\"].features.copy(deep=True), datasets[f\"{vehicle_class}_val\"].features.copy(deep=True), datasets[f\"{vehicle_class}_test\"].features.copy(deep=True)], ignore_index=True)\n",
    "    labels = pd.concat([datasets[f\"{vehicle_class}_train\"].labels.copy(deep=True), datasets[f\"{vehicle_class}_val\"].labels.copy(deep=True), datasets[f\"{vehicle_class}_test\"].labels.copy(deep=True)], ignore_index=True)\n",
    "    features[TARGET] = labels\n",
    "    data[vehicle_class] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_bootstrap(deepcopy(data), \n",
    "                        num_boot_runs, \n",
    "                        device, \n",
    "                        mtl_params, \n",
    "                        baseline_params, \n",
    "                        num_epochs, \n",
    "                        frac=1.0, \n",
    "                        replace=True, \n",
    "                        model_type=model_type)\n",
    "\n",
    "out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", f\"bootresults.pkl\")\n",
    "with open(out_path, 'wb') as handle:\n",
    "    pickle.dump(results, handle)\n",
    "\n",
    "saved_results = {}\n",
    "for m in model_type:\n",
    "    bias_diesel, biases_diesel = get_bias(data['diesel'], results[f\"{m}_diesel\"])\n",
    "    bias_hybrid, biases_hybrid = get_bias(data['hybrid'], results[f\"{m}_hybrid\"])\n",
    "    bias_electric, biases_electric = get_bias(data['electric'], results[f\"{m}_electric\"])\n",
    "    \n",
    "    ave_mae_diesel, maes_diesel = get_ave_mae(data['diesel'], results[f\"{m}_diesel\"])\n",
    "    ave_mae_hybrid, maes_hybrid = get_ave_mae(data['hybrid'], results[f\"{m}_hybrid\"])\n",
    "    ave_mae_electric, maes_electric = get_ave_mae(data['electric'], results[f\"{m}_electric\"])\n",
    "    \n",
    "    ave_mse_diesel, mses_diesel = get_ave_mse(data['diesel'], results[f\"{m}_diesel\"])\n",
    "    ave_mse_hybrid, mses_hybrid = get_ave_mse(data['hybrid'], results[f\"{m}_hybrid\"])\n",
    "    ave_mse_electric, mses_electric = get_ave_mse(data['electric'], results[f\"{m}_electric\"])\n",
    "    \n",
    "    saved_results[f\"{m}_bias\"] = [bias_diesel, bias_hybrid, bias_electric]\n",
    "    saved_results[f\"{m}_mae\"] = [ave_mae_diesel, ave_mae_hybrid, ave_mae_electric]\n",
    "    saved_results[f\"{m}_mse\"] = [ave_mse_diesel, ave_mse_hybrid, ave_mse_electric]\n",
    "    \n",
    "    box = {}\n",
    "    quantiles = [0.01, 0.25, 0.5, 0.75, 0.99]\n",
    "    box['diesel'] = pd.Series(biases_diesel).quantile(quantiles).tolist()\n",
    "    box['hybrid'] = pd.Series(biases_hybrid).quantile(quantiles).tolist()\n",
    "    box['electric'] = pd.Series(biases_electric).quantile(quantiles).tolist()\n",
    "    box_results = pd.DataFrame(box)\n",
    "    out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", f\"full_boot_{m}_bias_distribution.csv\")\n",
    "    box_results.to_csv(out_path, index=False)\n",
    "\n",
    "    mae_result = pd.DataFrame({'diesel': maes_diesel, 'hybrid': maes_hybrid, 'electric': maes_electric})\n",
    "    out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", f\"full_boot_{m}_mae_distribution.csv\")\n",
    "    mae_result.to_csv(out_path, index=False)\n",
    "\n",
    "    mse_result = pd.DataFrame({'diesel': mses_diesel, 'hybrid': mses_hybrid, 'electric': mses_electric})\n",
    "    out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", f\"full_boot_{m}_mse_distribution.csv\")\n",
    "    mse_result.to_csv(out_path, index=False)\n",
    "    \n",
    "df_temp = pd.DataFrame(saved_results, index=['diesel', 'hybrid', 'electric'])\n",
    "out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", \"full_boot.csv\")\n",
    "df_temp.to_csv(out_path, index_label='vehicle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-newark",
   "metadata": {},
   "source": [
    "## 8. ITL\n",
    "\n",
    "This is the ITL evaluation presented in Section 4.3 of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itl_iteration(source, \n",
    "                  target, \n",
    "                  baseline_params, \n",
    "                  target_frac,\n",
    "                  device,\n",
    "                  feature_extract=True, \n",
    "                  source_frac=0.9, \n",
    "                  num_epochs=150, \n",
    "                  num_runs=10):\n",
    "    \n",
    "    results = {'source': [], \n",
    "               'target': [], \n",
    "               'target_frac': [], \n",
    "               'target_samples': [], \n",
    "               'feature_extract': [], \n",
    "               'mse_target': [], \n",
    "               'mae_target': [], \n",
    "               'mse_baseline': [], \n",
    "               'mae_baseline': []}\n",
    "    \n",
    "    for num_run in range(num_runs):\n",
    "        source_datasets, source_datas = prepare_bootstrap_data(data, frac=source_frac, replace=False)\n",
    "        target_datasets, target_datas = prepare_bootstrap_data(data, frac=target_frac, replace=False)\n",
    "\n",
    "        # first train a baseline - source\n",
    "        df_results_source, model = train_baseline(source_datasets,\n",
    "                                                  source,\n",
    "                                                  baseline_params['n_hidden'], \n",
    "                                                  baseline_params['n_layers'], \n",
    "                                                  baseline_params['lr'], \n",
    "                                                  baseline_params['batch_size'], \n",
    "                                                  num_epochs, \n",
    "                                                  device, \n",
    "                                                  dropout=0,\n",
    "                                                  test=True, \n",
    "                                                  stats_at_epoch=1, \n",
    "                                                  early_stopping=False, \n",
    "                                                  early_stop_epochs=1000, \n",
    "                                                  metrics=['mse', 'mae', 'huber'], \n",
    "                                                  loss_fun=baseline_params['loss_fun'], \n",
    "                                                  filename=os.path.join(os.getcwd(), 'models', 'itlsource.pt'), \n",
    "                                                  val_on_train=False)\n",
    "    \n",
    "    \n",
    "        if feature_extract:\n",
    "            params_to_update = []\n",
    "            for name, param in model.named_parameters():\n",
    "                temp = name.split('.')[0]\n",
    "                if temp in ['v1', 'v2', 'v3', 'out']:\n",
    "                    params_to_update.append(param)\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "                #if param.requires_grad == True:\n",
    "                #    params_to_update.append(param)\n",
    "        else:\n",
    "            params_to_update = model.parameters()\n",
    "    \n",
    "        if baseline_params['opt'] == 'adam':\n",
    "            optimizer = torch.optim.Adam(params_to_update, lr=baseline_params['lr'])\n",
    "        else:\n",
    "            optimizer = torch.optim.AdamW(params_to_update, lr=baseline_params['lr'])\n",
    "        \n",
    "        # train target\n",
    "        df_results_target, model = train_baseline(target_datasets,\n",
    "                                                  target,\n",
    "                                                  baseline_params['n_hidden'], \n",
    "                                                  baseline_params['n_layers'], \n",
    "                                                  baseline_params['lr'], \n",
    "                                                  baseline_params['batch_size'], \n",
    "                                                  num_epochs, \n",
    "                                                  device, \n",
    "                                                  dropout=0,\n",
    "                                                  test=True, \n",
    "                                                  stats_at_epoch=1, \n",
    "                                                  early_stopping=False, \n",
    "                                                  early_stop_epochs=1000, \n",
    "                                                  metrics=['mse', 'mae', 'huber'], \n",
    "                                                  loss_fun=baseline_params['loss_fun'], \n",
    "                                                  filename=os.path.join(os.getcwd(), 'models', 'itltarget.pt'), \n",
    "                                                  val_on_train=False,\n",
    "                                                 model=model, \n",
    "                                                  optimizer=optimizer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # train baseline\n",
    "\n",
    "        baseline_model = BaselineModel(len(FEATURE_COLUMNS), baseline_params['n_hidden'], 1, 0, baseline_params['n_layers']).to(device)\n",
    "        if baseline_params['opt'] == 'adam':\n",
    "            baseline_optimizer = torch.optim.Adam(baseline_model.parameters(), lr=baseline_params['lr'])\n",
    "        else:\n",
    "            baseline_optimizer = torch.optim.AdamW(baseline_model.parameters(), lr=baseline_params['lr'])\n",
    "\n",
    "    \n",
    "        df_results_baseline, baseline_model = train_baseline(target_datasets,\n",
    "                                                            target,\n",
    "                                                              baseline_params['n_hidden'], \n",
    "                                                              baseline_params['n_layers'], \n",
    "                                                              baseline_params['lr'], \n",
    "                                                              baseline_params['batch_size'], \n",
    "                                                              num_epochs, \n",
    "                                                              device, \n",
    "                                                              dropout=0,\n",
    "                                                              test=True, \n",
    "                                                              stats_at_epoch=1, \n",
    "                                                          early_stopping=False, \n",
    "                                                          early_stop_epochs=1000, \n",
    "                                                          metrics=['mse', 'mae', 'huber'], \n",
    "                                                          loss_fun=baseline_params['loss_fun'], \n",
    "                                                          filename=os.path.join(os.getcwd(), 'models', 'itlbase.pt'), \n",
    "                                                          val_on_train=False,\n",
    "                                                         model=baseline_model, \n",
    "                                                         optimizer=baseline_optimizer)\n",
    "    \n",
    "        results['source'].append(source)\n",
    "        results['target'].append(target)\n",
    "        results['target_frac'].append(target_frac)\n",
    "        results['target_samples'].append(len(target_datas[f\"df_train_{target}\"]))\n",
    "        results['feature_extract'].append(feature_extract)\n",
    "        results['mse_target'].append(df_results_target['test_mse'].min())\n",
    "        results['mae_target'].append(df_results_target['test_mae'].min())\n",
    "        results['mse_baseline'].append(df_results_baseline['test_mse'].min())\n",
    "        results['mae_baseline'].append(df_results_baseline['test_mae'].min())\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_params = {'opt': 'adam', 'loss_fun': 'mse', 'n_hidden': 300, 'n_layers': 5, 'lr': 0.0005, 'batch_size': 256}\n",
    "target_fracs = [0.02, 0.05, 0.1, 0.15]\n",
    "device = torch.device('cuda:1')\n",
    "results = []\n",
    "vehicles = ['diesel', 'hybrid', 'electric']\n",
    "for source in vehicles:\n",
    "    for target in vehicles:\n",
    "        if source != target:\n",
    "            for target_frac in target_fracs:\n",
    "                #out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", \"itl_temp.csv\")\n",
    "                #temp = pd.read_csv(out_path)\n",
    "                #if len(temp[(temp['source']==source) & (temp['target']==target) & (temp['target_frac']==target_frac)]) > 0:\n",
    "                #    print('continue')\n",
    "                #    continue\n",
    "                start_time = time.time()\n",
    "                df = itl_iteration(source, target, baseline_params, target_frac, device)\n",
    "                results.append(df)\n",
    "                end_time = time.time() - start_time\n",
    "                print(f\"Done with source: {source}, target: {target}, target_frac: {target_frac}, took {end_time} seconds\")\n",
    "                if len(results) > 1:\n",
    "                    out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", \"itl_temp.csv\")\n",
    "                    temp = pd.concat(results, ignore_index=True)\n",
    "                    temp.to_csv(out_path, index=False)\n",
    "                \n",
    "out_path = os.path.join(os.getcwd(), \"output_r\", \"latex\", \"itl.csv\")\n",
    "temp = pd.concat(results, ignore_index=True)\n",
    "temp.to_csv(out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, datas = prepare_bootstrap_data(data, frac=0.8, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-cartoon",
   "metadata": {},
   "source": [
    "## 9. t-SNE Visualization\n",
    "\n",
    "This corresponds with the discussion Section 4.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diesel\n",
    "num_epochs = 20\n",
    "device = torch.device('cuda:2')\n",
    "baseline_params = {'opt': 'adamw', 'loss_fun': 'mse', 'n_hidden': 300, 'n_layers': 5, 'lr': 0.0005, 'batch_size': 256}\n",
    "\n",
    "datasets, datas = prepare_bootstrap_data(data, frac=0.8, replace=False)\n",
    "#target_datasets, target_datas = prepare_bootstrap_data(data, frac=target_frac, replace=False)\n",
    "\n",
    "# diesel\n",
    "df_results_diesel, model_diesel = train_baseline(datasets,\n",
    "                                            'diesel',\n",
    "                                                  baseline_params['n_hidden'], \n",
    "                                                  baseline_params['n_layers'], \n",
    "                                                  baseline_params['lr'], \n",
    "                                                  baseline_params['batch_size'], \n",
    "                                                  num_epochs, \n",
    "                                                  device, \n",
    "                                                  dropout=0,\n",
    "                                                  test=True, \n",
    "                                                  stats_at_epoch=1, \n",
    "                                                  early_stopping=False, \n",
    "                                                  early_stop_epochs=1000, \n",
    "                                                  metrics=['mse', 'mae', 'huber'], \n",
    "                                                  loss_fun=baseline_params['loss_fun'], \n",
    "                                                  filename=os.path.join(os.getcwd(), 'models', 'tnsediesel.pt'), \n",
    "                                                  val_on_train=False)\n",
    "\n",
    "df_results_hybrid, model_hybrid = train_baseline(datasets,\n",
    "                                            'hybrid',\n",
    "                                                  baseline_params['n_hidden'], \n",
    "                                                  baseline_params['n_layers'], \n",
    "                                                  baseline_params['lr'], \n",
    "                                                  baseline_params['batch_size'], \n",
    "                                                  num_epochs, \n",
    "                                                  device, \n",
    "                                                  dropout=0,\n",
    "                                                  test=True, \n",
    "                                                  stats_at_epoch=1, \n",
    "                                                  early_stopping=False, \n",
    "                                                  early_stop_epochs=1000, \n",
    "                                                  metrics=['mse', 'mae', 'huber'], \n",
    "                                                  loss_fun=baseline_params['loss_fun'], \n",
    "                                                  filename=os.path.join(os.getcwd(), 'models', 'tnsehybrid.pt'), \n",
    "                                                  val_on_train=False)\n",
    "\n",
    "df_results_electric, model_electric = train_baseline(datasets,\n",
    "                                            'electric',\n",
    "                                                  baseline_params['n_hidden'], \n",
    "                                                  baseline_params['n_layers'], \n",
    "                                                  baseline_params['lr'], \n",
    "                                                  baseline_params['batch_size'], \n",
    "                                                  num_epochs, \n",
    "                                                  device, \n",
    "                                                  dropout=0,\n",
    "                                                  test=True, \n",
    "                                                  stats_at_epoch=1, \n",
    "                                                  early_stopping=False, \n",
    "                                                  early_stop_epochs=1000, \n",
    "                                                  metrics=['mse', 'mae', 'huber'], \n",
    "                                                  loss_fun=baseline_params['loss_fun'], \n",
    "                                                  filename=os.path.join(os.getcwd(), 'models', 'tnseelectric.pt'), \n",
    "                                                  val_on_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "\n",
    "# diesel\n",
    "model_path = os.path.join(os.getcwd(), 'models', 'tnsediesel.pt')\n",
    "device = torch.device('cuda:2')\n",
    "model_diesel = BaselineModel(len(FEATURE_COLUMNS), 300, 1, 0, 5)\n",
    "#baseline_model = MultiTaskModel(len(FEATURE_COLUMNS), 300, 5, [64, 32, 16], outlayer='linear')\n",
    "checkpoint = torch.load(model_path)\n",
    "model_diesel.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_diesel.double()\n",
    "model_diesel.to(device)\n",
    "\n",
    "# hybrid\n",
    "model_path = os.path.join(os.getcwd(), 'models', 'tnsehybrid.pt')\n",
    "device = torch.device('cuda:2')\n",
    "model_hybrid = BaselineModel(len(FEATURE_COLUMNS), 300, 1, 0, 5)\n",
    "#baseline_model = MultiTaskModel(len(FEATURE_COLUMNS), 300, 5, [64, 32, 16], outlayer='linear')\n",
    "checkpoint = torch.load(model_path)\n",
    "model_hybrid.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_hybrid.double()\n",
    "model_hybrid.to(device)\n",
    "\n",
    "# electric\n",
    "model_path = os.path.join(os.getcwd(), 'models', 'tnseelectric.pt')\n",
    "device = torch.device('cuda:2')\n",
    "model_electric = BaselineModel(len(FEATURE_COLUMNS), 300, 1, 0, 5)\n",
    "#baseline_model = MultiTaskModel(len(FEATURE_COLUMNS), 300, 5, [64, 32, 16], outlayer='linear')\n",
    "checkpoint = torch.load(model_path)\n",
    "model_electric.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_electric.double()\n",
    "model_electric.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#quantiles = [0.01, 0.2, 0.4, 0.6, 0.8, 0.99]\n",
    "#colors = ['midnightblue', 'mediumblue', 'mediumpurple', 'violet', 'crimson']\n",
    "\n",
    "def get_color(x, quant, colors):\n",
    "    result = None\n",
    "    for i in range(1, len(quant)):\n",
    "        if (x >= quant[i-1]) & (x < quant[i]):\n",
    "            result = colors[i-1]\n",
    "    return result\n",
    "\n",
    "(fig, subplots) = plt.subplots(3, 3, figsize=(15, 10.5))\n",
    "\n",
    "vehicle_types = ['diesel', 'hybrid', 'electric']\n",
    "for i in range(len(vehicle_types)):\n",
    "    source = vehicle_types[i]\n",
    "    if source == 'diesel':\n",
    "        model = model_diesel\n",
    "    elif source == 'hybrid':\n",
    "        model = model_hybrid\n",
    "    else:\n",
    "        model = model_electric\n",
    "    for j in range(len(vehicle_types)):\n",
    "        target = vehicle_types[j]\n",
    "        df = datas[f\"df_train_{target}\"]\n",
    "        quant = df['target_kg'].quantile([0.1, 0.9]).tolist()  \n",
    "        norm = Normalize(vmin=quant[0], vmax=quant[-1], clip=True)\n",
    "        mapper = cm.ScalarMappable(norm=norm, cmap=cm.plasma)\n",
    "        samples = df.sample(frac=.02, replace=False, random_state=100)\n",
    "        samples['color'] = samples['target_kg'].apply(lambda x: mapper.to_rgba(x))\n",
    "        #samples = samples.dropna()\n",
    "        features = torch.tensor(samples[FEATURE_COLUMNS].values).double().to(device)\n",
    "        predicts = model.feature_extractor(features).cpu().detach().numpy()\n",
    "        X = TSNE(n_components=2, perplexity=10, init='pca').fit_transform(predicts)\n",
    "        \n",
    "        ax = subplots[i][j]\n",
    "        if source == 'diesel':\n",
    "            title1 = 'ICEV'\n",
    "        elif source == 'hybrid':\n",
    "            title1 = 'HV'\n",
    "        else:\n",
    "            title1 = 'EV'\n",
    "        if target == 'diesel':\n",
    "            title2 = 'ICEV'\n",
    "        elif target == 'hybrid':\n",
    "            title2 = 'HV'\n",
    "        else:\n",
    "            title2 = 'EV'\n",
    "        ax.set_title(f\"Source: {title1}, Target: {title2}\", fontsize=18)\n",
    "        ax.scatter(X[:,0], X[:,1], c=samples['color'])\n",
    "        ax.xaxis.set_major_formatter(NullFormatter())\n",
    "        ax.yaxis.set_major_formatter(NullFormatter())\n",
    "        ax.axis('tight')\n",
    "plt.subplots_adjust(hspace = .3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#quantiles = [0.01, 0.2, 0.4, 0.6, 0.8, 0.99]\n",
    "#colors = ['midnightblue', 'mediumblue', 'mediumpurple', 'violet', 'crimson']\n",
    "\n",
    "def get_color(x, quant, colors):\n",
    "    result = None\n",
    "    for i in range(1, len(quant)):\n",
    "        if (x >= quant[i-1]) & (x < quant[i]):\n",
    "            result = colors[i-1]\n",
    "    return result\n",
    "\n",
    "(fig, subplots) = plt.subplots(1, 3, figsize=(15, 3))\n",
    "\n",
    "vehicle_types = ['diesel', 'hybrid', 'electric']\n",
    "for i in range(len(vehicle_types)):\n",
    "    source = vehicle_types[i]\n",
    "    if source == 'diesel':\n",
    "        model = model_diesel\n",
    "    elif source == 'hybrid':\n",
    "        model = model_hybrid\n",
    "    else:\n",
    "        model = model_electric\n",
    "    #for j in range(len(vehicle_types)):\n",
    "    target = source\n",
    "    df = datas[f\"df_train_{target}\"]\n",
    "    quant = df['target_kg'].quantile([0.1, 0.9]).tolist()  \n",
    "    norm = Normalize(vmin=quant[0], vmax=quant[-1], clip=True)\n",
    "    mapper = cm.ScalarMappable(norm=norm, cmap=cm.plasma)\n",
    "    samples = df.sample(frac=.02, replace=False, random_state=100)\n",
    "    samples['color'] = samples['target_kg'].apply(lambda x: mapper.to_rgba(x))\n",
    "\n",
    "    X = TSNE(n_components=2, perplexity=10, init='pca').fit_transform(samples[FEATURE_COLUMNS].values)\n",
    "        \n",
    "    ax = subplots[i]\n",
    "    if source == 'diesel':\n",
    "        title1 = 'ICEV'\n",
    "    elif source == 'hybrid':\n",
    "        title1 = 'HV'\n",
    "    else:\n",
    "        title1 = 'EV'\n",
    "    ax.set_title(title1, fontsize=18)\n",
    "    ax.scatter(X[:,0], X[:,1], c=samples['color'])\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    ax.axis('tight')\n",
    "#plt.subplots_adjust(hspace = .3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(os.getcwd(), \"output_r\", \"images\", \"tsnefeatureextract.png\")\n",
    "fig.savefig(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=samples['quantile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datas[\"df_train_diesel\"]\n",
    "minima = df['target_kg'].min()\n",
    "maxima = df['target_kg'].max()\n",
    "print(minima, maxima)\n",
    "\n",
    "norm = Normalize(vmin=minima, vmax=maxima, clip=True)\n",
    "mapper = cm.ScalarMappable(norm=norm, cmap=cm.plasma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.to_rgba(0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-bachelor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
